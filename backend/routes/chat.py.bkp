# backend/routes/chat.py
from fastapi import APIRouter, HTTPException
from fastapi.responses import StreamingResponse
from pydantic import BaseModel, Field
import httpx, logging, os, uuid, datetime as dt

router = APIRouter()
SUPER_URL = "http://127.0.0.1:9191/super"      # already running
CHAT_LOG  = os.getenv("CHAT_LOG", "backend/logs/chat.log")

class ChatReq(BaseModel):
    text: str = Field(..., description="User prompt")
    mode: str = Field("sop", pattern="^(sop|rca|ticket)$")

@router.post("/chat")
async def chat(req: ChatReq):
    payload = {
        "mode": req.mode,
        "payload": {"topic": req.text}
    }
    async with httpx.AsyncClient(timeout=45) as client:
        try:
            res = await client.post(SUPER_URL, json=payload)
            res.raise_for_status()
            data = res.json()
        except Exception as e:
            logging.exception("chatâ†’super error")
            raise HTTPException(502, f"Agent error: {e}")

    # ---- simple log ----
    line = {
        "id": uuid.uuid4().hex,
        "ts": dt.datetime.utcnow().isoformat(),
        "mode": req.mode,
        "question": req.text,
        "answer": data,
    }
    with open(CHAT_LOG, "a") as fp:
        fp.write(f"{line}\n")

    # Return only the first value (agent answer)
    return list(data.values())[0]
        
@router.get("/chat/stream")
async def chat_stream(text: str, mode: str = "sop"):
    """Server-Sent Events stream so the FE can render tokens chunk-by-chunk."""
    payload = {"mode": mode, "payload": {"topic": text}}
    async def event_generator():
        async with httpx.AsyncClient(timeout=None) as client:
            async with client.stream("POST", SUPER_URL, json=payload) as res:
                async for chunk in res.aiter_text():
                    yield f"data:{chunk}\n\n"
        yield "data:[END]\n\n"

    return StreamingResponse(event_generator(),
                             media_type="text/event-stream",
                             headers={"Cache-Control": "no-cache"})