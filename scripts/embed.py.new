#!/usr/bin/env python
"""Split cleaned markdown, embed with bge-base, store in Chroma."""

from pathlib import Path
from logconf import logging
import json, hashlib, chromadb
from sentence_transformers import SentenceTransformer
from langchain.text_splitter import RecursiveCharacterTextSplitter
from rich.progress import Progress, SpinnerColumn, TextColumn

# === Paths ===
BASE   = Path(__file__).resolve().parent.parent
TXT    = BASE / "clean"
DBPATH = (BASE / "vector_store").expanduser()

# === Chroma Setup ===
client = chromadb.PersistentClient(path=str(DBPATH))
collection = client.get_or_create_collection("knowledge_base")

# === Text Splitter & Embedding Model ===
splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=80)
model    = SentenceTransformer("BAAI/bge-base-en", device="mps")

# === Run ===
with Progress(
    SpinnerColumn(),
    TextColumn("[bold blue]Embedding: {task.fields[filename]}"),
    transient=True
) as progress:
    for jf in TXT.glob("*.json"):
        doc = json.loads(jf.read_text())
        task = progress.add_task("embed", filename=jf.name)
        chunks = splitter.split_text(doc["body"])

        for chunk in chunks:
            cid = hashlib.md5(chunk.encode()).hexdigest()
            try:
                collection.add(
                    documents=[chunk],
                    metadatas=[{"src": doc["source"]}],
                    ids=[cid],
                )
            except ValueError:
                logging.debug(f"‚Ü©Ô∏è Duplicate chunk skipped {cid}")

        progress.update(task, completed=1)
        logging.info(f"üìå Embedded {jf.name} with {len(chunks)} chunks")

logging.info("‚úÖ Embedding complete")